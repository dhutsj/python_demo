# my global config
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  scrape_timeout:      10s # scrape_timeout is set to the global default (10s).

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
    - targets: ['localhost:9090']

  - job_name: 'otel-python-demo'
    scrape_interval: 5s
    static_configs:
      - targets: ['localhost:8000']

# remote_write:
#   - url: https://metric-api.newrelic.com/prometheus/v1/write?prometheus_server=tsj_mac_prometheus
#     bearer_token: xxxxxxx
#   - url: "https://cn-shanghai.arms.aliyuncs.com/prometheus/1304828673647156/c1fcc177c0770447492556985e3459d57/cn-shanghai/api/v3/write"
#     basic_auth:
#       username: xxxxxxx
#       password: xxxxxxx

# remote_read:
#   - url: "https://cn-shanghai.arms.aliyuncs.com:9443/api/v1/prometheus/9c8cc1e95b96358080e66cd836f3f062/1304828673647156/c1fcc177c0770447492556985e3459d57/cn-shanghai/api/v1/read"
#     read_recent: true
